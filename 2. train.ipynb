{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Uczenie modeli\n",
    "\n",
    "Niniejszy skrypt służy w celu imitowania konsoli i dyskusji na temat skryptu do eksperymentów i uczenia modeli - `train.py`. Opisane w niej również będą użyte techniki MLOps oraz zastosowane praktyki CI/CD. \n",
    "\n",
    "Proces stworzenia dobrego skryptów/systemu z CI/CD (w zależności od używanych technologii) jest czasochłonny i wymaga przemyślenia wielu koncepcji. Na przykłądzie zadania 6.2 z PolEval chciałbym pokazać tylko pewną część działania, na podstawie której chciałbym podyskutować i omówić co chciałbym zrobić w dalszych krokach.\n",
    "\n",
    "Z racji tego, że pracuje lokalnie, tzn. na moim prywatnym laptopie, decyduje się na użycie [MLflow](https://mlflow.org/).\n",
    "\n",
    "Tak jak mówiłem, niniejszy Notebook służy jako imitację konsoli, a pod spodem widzimy log z operacji wykonywanych w zdefiniowanym przeze mnie ML Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-20 09:31:30,759 - INFO - Collecting new data\n",
      "2021-07-20 09:31:30,782 - INFO - New data collected\n",
      "2021-07-20 09:31:30,783 - INFO - Data verification and validation\n",
      "2021-07-20 09:31:30,835 - INFO - Starting MLFlow run: Support Vector Classifier v01\n",
      "2021-07-20 09:31:30,857 - INFO - Creating validation set\n",
      "2021-07-20 09:31:30,868 - INFO - Creating cleaning pipeline\n",
      "2021-07-20 09:31:30,891 - INFO - Fitting cleaning pipeline and transforming training set\n",
      "2021-07-20 09:31:32,388 - INFO - Transforming validation set\n",
      "2021-07-20 09:31:33,031 - INFO - Performing hyperparatemer optimization\n",
      "2021-07-20 09:31:33,035 - INFO - Hyperparatemer optimization completed. Best params are: tfidf: {'encoding': 'utf-8', 'decode_error': 'strict', 'strip_accents': None, 'lowercase': False, 'preprocessor': None, 'tokenizer': None, 'analyzer': 'word', 'stop_words': None, 'token_pattern': '(?u)\\\\b\\\\w\\\\w\\\\w+\\\\b|[^\\\\x00-\\\\x7F]', 'ngram_range': (1, 1), 'max_df': 0.95, 'min_df': 5} ml model: {'C': 1.0, 'kernel': 'poly', 'degree': 3}\n",
      "2021-07-20 09:31:33,035 - INFO - Creating ML model pipeline\n",
      "2021-07-20 09:31:33,036 - INFO - Fitting ML model\n",
      "2021-07-20 09:31:34,774 - INFO - Performing check on training data\n",
      "2021-07-20 09:31:34,775 - INFO - Predicting training set\n",
      "2021-07-20 09:31:35,362 - INFO - Evaluating training set\n",
      "2021-07-20 09:31:35,380 - INFO - Performing check on validation data\n",
      "2021-07-20 09:31:35,380 - INFO - Predicting validation set\n",
      "2021-07-20 09:31:35,620 - INFO - Evaluating validation set\n",
      "2021-07-20 09:31:35,629 - INFO - F1 micro average -> train set = 0.9740, validation set = 0.9210\n",
      "2021-07-20 09:31:35,629 - INFO - Performing check on test data\n",
      "2021-07-20 09:31:35,630 - INFO - Fitting cleaning pipeline and transforming training set on full data\n",
      "2021-07-20 09:31:37,026 - INFO - Transforming test set\n",
      "2021-07-20 09:31:37,166 - INFO - Fitting ML model on full data\n",
      "2021-07-20 09:31:41,301 - INFO - Predicting test set\n",
      "2021-07-20 09:31:41,429 - INFO - Evaluating test set\n",
      "2021-07-20 09:31:41,433 - INFO - Checking new ML model vs. production ML model\n",
      "2021-07-20 09:31:41,433 - INFO - F1 micro average -> New model = 0.8690, Production = 0.8690, Baseline = 0.8660\n",
      "2021-07-20 09:31:41,434 - INFO - Ended MLFlow run: Support Vector Classifier v01 after 10.60 seconds = 0.18 minutes = 0.00 hours\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest on przykładem działania pipeline'a, w którym nie ma jeszcze zaimplementowanych wszystkich elementów aby móc powiedzieć o pełnym CI/CD, o których teraz chciałbym wspomnieć:\n",
    "\n",
    "1. Data versioning - wersjonowanie danych, by można było określić na jakich zbiorach modele były uczone i testowane. MLFlow pozwala mi na zrzut danych jako artefaktów i w każdym przebiegu pipeline są one zapisywane. \n",
    "2. Data verification/validation - innymi słowy, badanie jakości danych na których uczymy model i porównanie ich z danymi uczacymi na ktorych uczony był model na produkcji. W tym etapie możnaby zbadać covariate shift, tzn. różnice w rozkładach słów i emotikonek między danymi użytymi do nauki tego modelu vs. dane użyte do modeli na produkcji oraz concept drift, tzn. jak rozkłady kategorii *non-harmful*, *hate-speech* i *cyberbullying* uległy zmianie w porównianu do zbiorów uczących modelu na produkcji.\n",
    "3. Model analysis/evaluation - Czyli nauka modelu wraz z optymalizacją hiperparametrów. Tego etapu jeszcze brak, użyłbym w nim [optuny i jej intergracji z MLflow](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.MLflowCallback.html)\n",
    "4. Model validation - Porównanie z obecnym modelem na produkcji oraz z baselinem. Obecnie zaimplementowane jest tylko porównanie na bazie miary F1 micro-average score. To co dodałbym jeszcze to porównanie czasu inferencji oraz \"zasobożerność\", tzn. ile pamięci potrzeba, zużycie CPU (lub GPU w zależności od testowanego modelu).\n",
    "\n",
    "MLFlow pozwala na zarządzanie metadanymi i rejestrem - ze wszystkich etapów zrzucane są użyte dane, pipeline'y do czyszczenia i uczenia modelu, wartości miar na bazie których porównywano model wraz z parametrami (w folderze `./mlruns/`). W wyniku przebiegu otrzymujemy wszystkie elementy niezbędne do wdrożenia zbudowanego za pomocą skryptu `train.py` modelu.\n",
    "\n",
    "Scenariusze kiedy mógłby być używany pipeline:\n",
    "\n",
    "1. Ręcznie, podczas eksperymentowania i pracy nad kolejnymi rozwiązaniami\n",
    "2. Zgodnie z przyjętym harmonogramem - uczymy model co pewien określony czas\n",
    "3. Gdy \"pojawią się\" nowe dane\n",
    "4. Gdy jakość modelu drastycznie spadła (np. o określoną wartość f1 micro-average)\n",
    "5. Gdy obserwowane są duże zmiany w rozkładach słów (covariate shift) i/lub rozkładach kategorii (concept drift).\n",
    "\n",
    "Do punktu 3., 4. i 5. niezbędne byłoby stworzenie cyklicznego monitoringu jakości modelu i danych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W kolejnym notebooku - `deployment.ipynb` (który podobnie jak ten notebook) imituje konsole, omówimy proces wdrożenia rozwiązania, które stworzyliśmy korzystając z `train.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
